/**
 * AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
 * Generated by scripts/generate-model-config.js from config/models.json
 * Last updated: 2025-12-28T01:14:58.120Z
 */

const MODELS = [
  {
    "id": "gpt-5.2",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5.2",
    "description": "Best model for coding and agentic tasks across industries",
    "year": 2025,
    "contextWindow": 400000,
    "maxOutput": 128000,
    "status": "available",
    "recommended": false,
    "order": 1
  },
  {
    "id": "gpt-5.1",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5.1",
    "description": "Flagship model for coding and agentic tasks with configurable reasoning effort",
    "year": 2025,
    "contextWindow": 400000,
    "maxOutput": 128000,
    "status": "available",
    "recommended": false,
    "order": 2
  },
  {
    "id": "gpt-5-pro",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5 Pro",
    "description": "Extended reasoning for most complex tasks",
    "year": 2025,
    "contextWindow": 400000,
    "maxOutput": 128000,
    "status": "available",
    "recommended": false,
    "order": 3
  },
  {
    "id": "gpt-5",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5",
    "description": "Most advanced model for coding and agentic tasks",
    "year": 2025,
    "contextWindow": 400000,
    "maxOutput": 128000,
    "status": "available",
    "recommended": false,
    "order": 4
  },
  {
    "id": "gpt-5-mini",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5 Mini",
    "description": "Faster, cost-efficient version",
    "year": 2025,
    "contextWindow": 200000,
    "maxOutput": 64000,
    "status": "available",
    "recommended": false,
    "order": 5
  },
  {
    "id": "gpt-5-nano",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5 Nano",
    "description": "Fastest, most cost-efficient version",
    "year": 2025,
    "contextWindow": 128000,
    "maxOutput": 32000,
    "status": "available",
    "recommended": false,
    "order": 6
  },
  {
    "id": "gemini-3-pro-preview",
    "provider": "google",
    "client": "GeminiClient",
    "displayName": "Gemini 3 Pro",
    "description": "Most advanced multimodal AI with thinking capabilities",
    "year": 2025,
    "contextWindow": 1048576,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 7
  },
  {
    "id": "gemini-3-flash-preview",
    "provider": "google",
    "client": "GeminiClient",
    "displayName": "Gemini 3 Flash",
    "description": "Fast multimodal AI with thinking capabilities",
    "year": 2025,
    "contextWindow": 1048576,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 8
  },
  {
    "id": "gemini-2.5-pro",
    "provider": "google",
    "client": "GeminiClient",
    "displayName": "Gemini 2.5 Pro",
    "description": "State-of-the-art thinking model",
    "year": 2025,
    "contextWindow": 1048576,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 9
  },
  {
    "id": "gemini-2.5-flash",
    "provider": "google",
    "client": "GeminiClient",
    "displayName": "Gemini 2.5 Flash",
    "description": "Best price-performance with thinking",
    "year": 2025,
    "contextWindow": 1048576,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 10
  },
  {
    "id": "claude-sonnet-4-5-20250929",
    "provider": "anthropic",
    "client": "ClaudeClient",
    "displayName": "Claude 4.5 Sonnet",
    "description": "RECOMMENDED for complex agents",
    "year": 2025,
    "contextWindow": 200000,
    "contextWindowBeta": 1000000,
    "maxOutput": 64000,
    "status": "available",
    "recommended": true,
    "order": 11
  },
  {
    "id": "claude-opus-4-5",
    "provider": "anthropic",
    "client": "ClaudeClient",
    "displayName": "Claude 4.5 Opus",
    "description": "Premium model combining maximum intelligence with practical performance",
    "year": 2025,
    "contextWindow": 200000,
    "maxOutput": 64000,
    "status": "available",
    "recommended": false,
    "order": 12
  },
  {
    "id": "claude-haiku-4-5",
    "provider": "anthropic",
    "client": "ClaudeClient",
    "displayName": "Claude 4.5 Haiku",
    "description": "Fastest model with near-frontier intelligence",
    "year": 2025,
    "contextWindow": 200000,
    "maxOutput": 64000,
    "status": "available",
    "recommended": false,
    "order": 13
  },
  {
    "id": "grok-4-1-fast-reasoning",
    "provider": "xai",
    "client": "GrokClient",
    "displayName": "Grok 4.1 Fast",
    "description": "Frontier multimodal model optimized for high-performance agentic tool calling",
    "year": 2025,
    "contextWindow": 2000000,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 14
  },
  {
    "id": "grok-4-fast-reasoning",
    "provider": "xai",
    "client": "GrokClient",
    "displayName": "Grok 4 Fast Reasoning",
    "description": "Fast reasoning with 2M context",
    "year": 2025,
    "contextWindow": 2000000,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 15
  },
  {
    "id": "qwen/qwen3-coder",
    "provider": "openrouter",
    "client": "OpenRouterClient",
    "displayName": "Qwen3 Coder",
    "description": "Specialized coding model via OpenRouter",
    "year": 2024,
    "contextWindow": 32768,
    "maxOutput": 8192,
    "status": "available",
    "recommended": false,
    "order": 16
  },
  {
    "id": "z-ai/glm-4.7",
    "provider": "openrouter",
    "client": "OpenRouterClient",
    "displayName": "GLM 4.7",
    "description": "High-performance AI model via OpenRouter",
    "year": 2024,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "status": "available",
    "recommended": false,
    "order": 17
  },
  {
    "id": "minimax/minimax-m2",
    "provider": "openrouter",
    "client": "OpenRouterClient",
    "displayName": "MiniMax M2",
    "description": "Compact high-efficiency model optimized for coding and agentic workflows",
    "year": 2025,
    "contextWindow": 196608,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 18
  },
  {
    "id": "deepseek/deepseek-v3.2",
    "provider": "openrouter",
    "client": "OpenRouterClient",
    "displayName": "DeepSeek V3.2",
    "description": "High computational efficiency with strong reasoning and agentic tool-use performance",
    "year": 2025,
    "contextWindow": 163840,
    "maxOutput": 32768,
    "status": "available",
    "recommended": false,
    "order": 19
  }
];

const PROVIDER_INFO = {
  "openai": {
    "name": "OpenAI",
    "apiKeyEnvVar": "OPENAI_API_KEY"
  },
  "anthropic": {
    "name": "Anthropic",
    "apiKeyEnvVar": "ANTHROPIC_API_KEY"
  },
  "google": {
    "name": "Google",
    "apiKeyEnvVar": "GOOGLE_API_KEY"
  },
  "xai": {
    "name": "xAI",
    "apiKeyEnvVar": "XAI_API_KEY"
  },
  "ollama": {
    "name": "Ollama",
    "apiKeyEnvVar": null
  },
  "openrouter": {
    "name": "OpenRouter",
    "apiKeyEnvVar": "OPENROUTER_API_KEY"
  }
};

/**
 * Model configuration manager
 */
class ModelConfig {
  /**
   * Get configuration for a specific model
   * @param {string} modelId - The model ID
   * @returns {Object | undefined} Model configuration
   */
  static get(modelId) {
    return MODELS.find(m => m.id === modelId);
  }

  /**
   * Get all active (non-deprecated) models
   * @returns {Array} Array of active model configurations
   */
  static getAllActive() {
    return MODELS.filter(m => m.status === 'available').sort((a, b) => a.order - b.order);
  }

  /**
   * Get all models (including deprecated)
   * @returns {Array} Array of all model configurations
   */
  static getAll() {
    return [...MODELS];
  }

  /**
   * Get models by provider
   * @param {string} provider - Provider name (openai, anthropic, google, xai, ollama, openrouter)
   * @returns {Array} Array of model configurations for the provider
   */
  static getByProvider(provider) {
    return MODELS.filter(m => m.provider === provider);
  }

  /**
   * Get provider information
   * @param {string} provider - Provider name
   * @returns {Object | undefined} Provider information
   */
  static getProviderInfo(provider) {
    return PROVIDER_INFO[provider];
  }

  /**
   * Get recommended models
   * @returns {Array} Array of recommended model configurations
   */
  static getRecommended() {
    return MODELS.filter(m => m.recommended && m.status === 'available');
  }

  /**
   * Get client class name for a model
   * @param {string} modelId - The model ID
   * @returns {string | undefined} Client class name
   */
  static getClient(modelId) {
    const model = this.get(modelId);
    return model?.client;
  }

  /**
   * Get display name for a model
   * @param {string} modelId - The model ID
   * @returns {string} Display name or model ID if not found
   */
  static getDisplayName(modelId) {
    const model = this.get(modelId);
    return model?.displayName || modelId;
  }

  /**
   * Get provider name for a model
   * @param {string} modelId - The model ID
   * @returns {string | undefined} Provider name
   */
  static getProvider(modelId) {
    const model = this.get(modelId);
    if (!model) return undefined;
    return PROVIDER_INFO[model.provider]?.name;
  }
}

module.exports = {
  ModelConfig,
  MODELS,
  PROVIDER_INFO
};
