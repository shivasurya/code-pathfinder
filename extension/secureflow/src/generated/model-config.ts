/**
 * AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
 * Generated by scripts/generate-model-config.js from config/models.json
 * Last updated: 2025-12-28T01:14:58.120Z
 *
 * NOTE: If you need to use AIModel in other files, import it from this file
 * or re-export it (e.g., in settings-manager.ts: export type { AIModel } from './generated/model-config')
 */

export type AIModel =
  | 'gpt-5.2'
  | 'gpt-5.1'
  | 'gpt-5-pro'
  | 'gpt-5'
  | 'gpt-5-mini'
  | 'gpt-5-nano'
  | 'gemini-3-pro-preview'
  | 'gemini-3-flash-preview'
  | 'gemini-2.5-pro'
  | 'gemini-2.5-flash'
  | 'claude-sonnet-4-5-20250929'
  | 'claude-opus-4-5'
  | 'claude-haiku-4-5'
  | 'grok-4-1-fast-reasoning'
  | 'grok-4-fast-reasoning'
  | 'qwen/qwen3-coder'
  | 'z-ai/glm-4.7'
  | 'minimax/minimax-m2'
  | 'deepseek/deepseek-v3.2';

export interface ModelConfigType {
  id: AIModel;
  provider: 'openai' | 'anthropic' | 'google' | 'xai' | 'ollama' | 'openrouter';
  client: string;
  displayName: string;
  description: string;
  year: number;
  contextWindow: number;
  contextWindowBeta?: number;
  maxOutput: number;
  status: 'available' | 'deprecated';
  recommended: boolean;
  order: number;
}

const MODELS: ModelConfigType[] = [
  {
    "id": "gpt-5.2",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5.2",
    "description": "Best model for coding and agentic tasks across industries",
    "year": 2025,
    "contextWindow": 400000,
    "maxOutput": 128000,
    "status": "available",
    "recommended": false,
    "order": 1
  },
  {
    "id": "gpt-5.1",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5.1",
    "description": "Flagship model for coding and agentic tasks with configurable reasoning effort",
    "year": 2025,
    "contextWindow": 400000,
    "maxOutput": 128000,
    "status": "available",
    "recommended": false,
    "order": 2
  },
  {
    "id": "gpt-5-pro",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5 Pro",
    "description": "Extended reasoning for most complex tasks",
    "year": 2025,
    "contextWindow": 400000,
    "maxOutput": 128000,
    "status": "available",
    "recommended": false,
    "order": 3
  },
  {
    "id": "gpt-5",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5",
    "description": "Most advanced model for coding and agentic tasks",
    "year": 2025,
    "contextWindow": 400000,
    "maxOutput": 128000,
    "status": "available",
    "recommended": false,
    "order": 4
  },
  {
    "id": "gpt-5-mini",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5 Mini",
    "description": "Faster, cost-efficient version",
    "year": 2025,
    "contextWindow": 200000,
    "maxOutput": 64000,
    "status": "available",
    "recommended": false,
    "order": 5
  },
  {
    "id": "gpt-5-nano",
    "provider": "openai",
    "client": "OpenAIClient",
    "displayName": "GPT-5 Nano",
    "description": "Fastest, most cost-efficient version",
    "year": 2025,
    "contextWindow": 128000,
    "maxOutput": 32000,
    "status": "available",
    "recommended": false,
    "order": 6
  },
  {
    "id": "gemini-3-pro-preview",
    "provider": "google",
    "client": "GeminiClient",
    "displayName": "Gemini 3 Pro",
    "description": "Most advanced multimodal AI with thinking capabilities",
    "year": 2025,
    "contextWindow": 1048576,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 7
  },
  {
    "id": "gemini-3-flash-preview",
    "provider": "google",
    "client": "GeminiClient",
    "displayName": "Gemini 3 Flash",
    "description": "Fast multimodal AI with thinking capabilities",
    "year": 2025,
    "contextWindow": 1048576,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 8
  },
  {
    "id": "gemini-2.5-pro",
    "provider": "google",
    "client": "GeminiClient",
    "displayName": "Gemini 2.5 Pro",
    "description": "State-of-the-art thinking model",
    "year": 2025,
    "contextWindow": 1048576,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 9
  },
  {
    "id": "gemini-2.5-flash",
    "provider": "google",
    "client": "GeminiClient",
    "displayName": "Gemini 2.5 Flash",
    "description": "Best price-performance with thinking",
    "year": 2025,
    "contextWindow": 1048576,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 10
  },
  {
    "id": "claude-sonnet-4-5-20250929",
    "provider": "anthropic",
    "client": "ClaudeClient",
    "displayName": "Claude 4.5 Sonnet",
    "description": "RECOMMENDED for complex agents",
    "year": 2025,
    "contextWindow": 200000,
    "contextWindowBeta": 1000000,
    "maxOutput": 64000,
    "status": "available",
    "recommended": true,
    "order": 11
  },
  {
    "id": "claude-opus-4-5",
    "provider": "anthropic",
    "client": "ClaudeClient",
    "displayName": "Claude 4.5 Opus",
    "description": "Premium model combining maximum intelligence with practical performance",
    "year": 2025,
    "contextWindow": 200000,
    "maxOutput": 64000,
    "status": "available",
    "recommended": false,
    "order": 12
  },
  {
    "id": "claude-haiku-4-5",
    "provider": "anthropic",
    "client": "ClaudeClient",
    "displayName": "Claude 4.5 Haiku",
    "description": "Fastest model with near-frontier intelligence",
    "year": 2025,
    "contextWindow": 200000,
    "maxOutput": 64000,
    "status": "available",
    "recommended": false,
    "order": 13
  },
  {
    "id": "grok-4-1-fast-reasoning",
    "provider": "xai",
    "client": "GrokClient",
    "displayName": "Grok 4.1 Fast",
    "description": "Frontier multimodal model optimized for high-performance agentic tool calling",
    "year": 2025,
    "contextWindow": 2000000,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 14
  },
  {
    "id": "grok-4-fast-reasoning",
    "provider": "xai",
    "client": "GrokClient",
    "displayName": "Grok 4 Fast Reasoning",
    "description": "Fast reasoning with 2M context",
    "year": 2025,
    "contextWindow": 2000000,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 15
  },
  {
    "id": "qwen/qwen3-coder",
    "provider": "openrouter",
    "client": "OpenRouterClient",
    "displayName": "Qwen3 Coder",
    "description": "Specialized coding model via OpenRouter",
    "year": 2024,
    "contextWindow": 32768,
    "maxOutput": 8192,
    "status": "available",
    "recommended": false,
    "order": 16
  },
  {
    "id": "z-ai/glm-4.7",
    "provider": "openrouter",
    "client": "OpenRouterClient",
    "displayName": "GLM 4.7",
    "description": "High-performance AI model via OpenRouter",
    "year": 2024,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "status": "available",
    "recommended": false,
    "order": 17
  },
  {
    "id": "minimax/minimax-m2",
    "provider": "openrouter",
    "client": "OpenRouterClient",
    "displayName": "MiniMax M2",
    "description": "Compact high-efficiency model optimized for coding and agentic workflows",
    "year": 2025,
    "contextWindow": 196608,
    "maxOutput": 65536,
    "status": "available",
    "recommended": false,
    "order": 18
  },
  {
    "id": "deepseek/deepseek-v3.2",
    "provider": "openrouter",
    "client": "OpenRouterClient",
    "displayName": "DeepSeek V3.2",
    "description": "High computational efficiency with strong reasoning and agentic tool-use performance",
    "year": 2025,
    "contextWindow": 163840,
    "maxOutput": 32768,
    "status": "available",
    "recommended": false,
    "order": 19
  }
];

const PROVIDER_INFO: Record<string, { name: string; apiKeyEnvVar: string | null }> = {
  "openai": {
    "name": "OpenAI",
    "apiKeyEnvVar": "OPENAI_API_KEY"
  },
  "anthropic": {
    "name": "Anthropic",
    "apiKeyEnvVar": "ANTHROPIC_API_KEY"
  },
  "google": {
    "name": "Google",
    "apiKeyEnvVar": "GOOGLE_API_KEY"
  },
  "xai": {
    "name": "xAI",
    "apiKeyEnvVar": "XAI_API_KEY"
  },
  "ollama": {
    "name": "Ollama",
    "apiKeyEnvVar": null
  },
  "openrouter": {
    "name": "OpenRouter",
    "apiKeyEnvVar": "OPENROUTER_API_KEY"
  }
};

/**
 * Model configuration manager for VS Code extension
 */
export class ModelConfig {
  /**
   * Get configuration for a specific model
   */
  static get(modelId: string) {
    return MODELS.find(m => m.id === modelId);
  }

  /**
   * Get all active (non-deprecated) models
   */
  static getAllActive() {
    return MODELS.filter(m => m.status === 'available').sort((a, b) => a.order - b.order);
  }

  /**
   * Get all models (including deprecated)
   */
  static getAll() {
    return [...MODELS];
  }

  /**
   * Get models by provider
   */
  static getByProvider(provider: string) {
    return MODELS.filter(m => m.provider === provider);
  }

  /**
   * Get provider information
   */
  static getProviderInfo(provider: string) {
    return PROVIDER_INFO[provider];
  }

  /**
   * Get recommended models
   */
  static getRecommended() {
    return MODELS.filter(m => m.recommended && m.status === 'available');
  }

  /**
   * Get client class name for a model
   */
  static getClient(modelId: string) {
    const model = this.get(modelId);
    return model?.client;
  }

  /**
   * Get display name for a model
   */
  static getDisplayName(modelId: string) {
    const model = this.get(modelId);
    return model?.displayName || modelId;
  }

  /**
   * Get provider name for a model
   */
  static getProvider(modelId: string) {
    const model = this.get(modelId);
    if (!model) return undefined;
    return PROVIDER_INFO[model.provider]?.name;
  }
}
